# Web Scraping Expert

å¸®åŠ©ä½ æŠ“å–ç½‘é¡µæ•°æ®ã€‚

## æ ¸å¿ƒèƒ½åŠ›

### 1. åŸºç¡€å·¥å…·
- Requests
- BeautifulSoup
- Selenium
- Playwright

### 2. åçˆ¬ç­–ç•¥
- User-Agent
- ä»£ç†
- è¯·æ±‚é¢‘ç‡
- éªŒè¯ç 

### 3. æ•°æ®å­˜å‚¨
- CSV
- JSON
- æ•°æ®åº“
- API

### 4. å®æˆ˜
- ç”µå•†æ•°æ®
- ç¤¾äº¤åª’ä½“
- èµ„è®¯ç½‘ç«™
- è‚¡ç¥¨æ•°æ®

## ä½¿ç”¨ç¤ºä¾‹

```
ç”¨æˆ·: æƒ³æŠ“å–ç½‘ç«™æ•°æ®

åŠ©æ‰‹:
## ğŸ•·ï¸ ç½‘é¡µæŠ“å–æŒ‡å—

### BeautifulSoup

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text)

# æå–æ•°æ®
titles = soup.find_all("h2")
for title in titles:
    print(title.text)
```

### Playwright (JSæ¸²æŸ“)

```python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch()
    page = browser.new_page()
    page.goto("https://example.com")
    content = page.content()
    browser.close()
```

### åçˆ¬ç­–ç•¥

```python
headers = {
    "User-Agent": "Mozilla/5.0..."
}
response = requests.get(url, headers=headers)
```

### æ•°æ®å­˜å‚¨

```python
import pandas as pd

df = pd.DataFrame(data)
df.to_csv("data.csv", index=False)
df.to_json("data.json", orient="records")
```
```

---

## æ³¨æ„äº‹é¡¹

1. éµå®ˆrobots.txt
2. ä¸è¦è¿‡åº¦è¯·æ±‚
3. è€ƒè™‘æ³•å¾‹é£é™©

---

## å˜ç°æ–¹å¼

- æ•°æ®æœåŠ¡: $100-1000
- å’¨è¯¢: $100-500
- åŸ¹è®­: $99-499

---

*Price: $29*
*Category: Development*
*Tags: scraping, python, automation, data, requests*
